# 실험 요약 (Experiment Summary)

본 문서는 **신용카드 고객 세그먼트 분류 AI 경진대회**에서 진행한 주요 실험 결과를 요약한 자료입니다.  
각 실험은 전처리 방식, 모델 구성, 하이퍼파라미터, 성능 지표(F1-score)를 기준으로 기록하였습니다.

---

## 1️⃣ 데이터셋 및 전처리
- 총 표본: 약 240,000명
- 컬럼: 857개
- Target: Segment (다중분류)
- 전처리 규칙:
  - 50% 이상 결측 컬럼 제거
  - 20~50% 결측 → 상관 변수 기반 대체
  - 20% 이하 결측 → 최빈값/Unknown 처리
- 스케일링: 로그 변환 + StandardScaler
- 인코딩: LabelEncoder
- 대용량 처리: Dask DataFrame 활용

---

## 2️⃣ 주요 실험 결과 요약

| 실험명 | 데이터/전처리 | 모델 | 특이사항 | F1-score |
|--------|---------------|------|----------|----------|
| Baseline XGB | 원본 데이터 | XGBoost | 데이콘 baseline | **0.607 (Public)** |
| 결측치 변수 반영 | 패턴 변수 반영 | XGBoost | 결측 패턴 처리 | **0.625 (Public)** |
| 단일 모델 비교 | 20k 샘플링 | CatBoost | PCA 미적용 | **0.8893 (Val)** |
| 〃 | 20k 샘플링 | Logistic Regression | PCA 99% | **0.8645 (Val)** |
| 〃 | 20k 샘플링 | XGBoost | PCA 미적용 | 0.8880 (Val) |
| 〃 | 20k 샘플링 | Random Forest | PCA 미적용 | 0.8625 (Val) |
| 〃 | 20k 샘플링 | DNN | PCA 99% | 0.8623 (Val) |
| 〃 | 20k 샘플링 | MLP | PCA 99% | 0.8592 (Val) |
| 〃 | 20k 샘플링 | CNN | PCA 미적용 | 0.8601 (Val) |
| SOTA 1 | 20k 샘플링 | TabNet | pytorch-tabnet | 0.8285 (Test) |
| SOTA 2 | 20k 샘플링 | FT-Transformer | rtdl | 메모리 초과 (실패) |
| SOTA 3 | 20k 샘플링 | NODE | pytorch-tabular | 초기 실험 중 |
| 앙상블 조합1 | 20k 샘플링 | CatBoost + LogReg + MLP | Stacking (meta=LogReg) | **0.8936 (Val)** |
| 앙상블 조합1-1 | 20k 샘플링 | CatBoost + LogReg + MLP | Stacking (meta=CatBoost) | 0.8911 (Val) |
| 앙상블 조합3 | 20k 샘플링 | CatBoost + SVM + LightGBM | Stacking | 0.8887 (Val) |

---

## 3️⃣ 최종 성과
- Public Score: **0.64636 (75등)**
- Private Score: **0.6251 (58등, 상위 25%)**
- 내부 검증 F1 Best: **0.8936 (Stacking, meta=LogReg)**

---

## 4️⃣ 교훈 및 인사이트
- 결측치 패턴을 변수화하면 성능 향상 가능
- CatBoost 단일 모델이 강력하지만 앙상블로 추가 개선 가능
- Tabular 딥러닝 모델(TabNet, FT-Transformer, NODE)은 메모리/성능 대비 효과가 제한적
- 실무 적용 시 SHAP/XAI 기반 해석이 필수적임

---

## 5️⃣ 다음 단계
- Stratified K-Fold 교차검증
- Optuna 기반 하이퍼파라미터 최적화
- SHAP/XAI 기반 변수 해석
- Cost-sensitive Learning, Focal Loss 적용
