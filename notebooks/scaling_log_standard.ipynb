{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8832993-1af0-4592-9cea-8e308286b523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T11:44:48.227846Z",
     "iopub.status.busy": "2025-04-29T11:44:48.227231Z",
     "iopub.status.idle": "2025-04-29T11:48:04.448231Z",
     "shell.execute_reply": "2025-04-29T11:48:04.447619Z",
     "shell.execute_reply.started": "2025-04-29T11:44:48.227829Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df=pd.read_csv('train_cat_plus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3d42a3-bfe2-4b18-9076-ece800817806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T11:48:08.569928Z",
     "iopub.status.busy": "2025-04-29T11:48:08.569495Z",
     "iopub.status.idle": "2025-04-29T11:48:13.311900Z",
     "shell.execute_reply": "2025-04-29T11:48:13.311332Z",
     "shell.execute_reply.started": "2025-04-29T11:48:08.569906Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=[col for col in train_df.columns if col.startswith('Unnamed')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db51204a-7daa-4147-ba80-8a845b0fc3ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T11:48:18.660493Z",
     "iopub.status.busy": "2025-04-29T11:48:18.659999Z",
     "iopub.status.idle": "2025-04-29T11:48:19.059308Z",
     "shell.execute_reply": "2025-04-29T11:48:19.058901Z",
     "shell.execute_reply.started": "2025-04-29T11:48:18.660469Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def Scaler_data(df, save_path=None, batch_size=None):\n",
    "    \"\"\"\n",
    "    ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì— ëŒ€í•´ ë¡œê·¸ ë³€í™˜, ìŠ¤ì¼€ì¼ë§, ì´ìƒì¹˜(Inf ì²˜ë¦¬)ê¹Œì§€ ìˆ˜í–‰í•˜ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜.\n",
    "    ê²°ì¸¡ì¹˜ê°€ ì—†ë‹¤ê³  ê°€ì •.\n",
    "\n",
    "    Parameters:\n",
    "    - df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„\n",
    "    - save_path: ì €ì¥ ê²½ë¡œ ì§€ì • ì‹œ, ì „ì²˜ë¦¬ ì™„ë£Œ íŒŒì¼ CSVë¡œ ì €ì¥ (ê¸°ë³¸ê°’: None)\n",
    "    - batch_size: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: None)\n",
    "\n",
    "    Returns:\n",
    "    - ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„°í”„ë ˆì„\n",
    "    - ë¡œê·¸ ë³€í™˜ ì ìš©ëœ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
    "    - ìŒìˆ˜ê°’ì´ ì¡´ì¬í•œ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ë°ì´í„° ë³µì‚¬ (ìµœì†Œí™”)\n",
    "    df_processed = df.copy()  # ìµœì´ˆ ë³µì‚¬ë³¸ í•˜ë‚˜ë§Œ ìƒì„±\n",
    "    print(f\"âœ… ë°ì´í„° í¬ê¸°: {df_processed.shape}\")\n",
    "\n",
    "    # 2. ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ\n",
    "    numeric_cols = df_processed.select_dtypes(include=['number']).columns.tolist()\n",
    "    if not numeric_cols:\n",
    "        print(\"âš ï¸ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return df_processed, [], []\n",
    "\n",
    "    # 3. Inf ê°’ ì²˜ë¦¬\n",
    "    df_processed[numeric_cols] = df_processed[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    if df_processed[numeric_cols].isna().any().any():\n",
    "        print(\"âš ï¸ Inf ê°’ì„ NaNìœ¼ë¡œ ëŒ€ì²´ í›„, NaN ë°œìƒ. í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´.\")\n",
    "        df_processed[numeric_cols] = df_processed[numeric_cols].fillna(df_processed[numeric_cols].mean())\n",
    "    print(f\"âœ… Inf ì²˜ë¦¬ ì™„ë£Œ. ì²˜ë¦¬ëœ ì»¬ëŸ¼: {numeric_cols}\")\n",
    "\n",
    "    # 4. ë¡œê·¸ ë³€í™˜ì´ í•„ìš”í•œ ì»¬ëŸ¼ íƒì§€\n",
    "    log_transform_cols = []\n",
    "    cols_with_negative_values = []\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        col_min = df_processed[col].min()\n",
    "        col_max = df_processed[col].max()\n",
    "        if col_min < 0:\n",
    "            cols_with_negative_values.append(col)\n",
    "        if col_max > 1000 or (col_min > 0 and col_max / col_min > 50):\n",
    "            log_transform_cols.append(col)\n",
    "    print(f\"ğŸ“Š ë¡œê·¸ ë³€í™˜ ëŒ€ìƒ ì»¬ëŸ¼: {log_transform_cols}\")\n",
    "    print(f\"ğŸ“Š ìŒìˆ˜ ê°’ í¬í•¨ ì»¬ëŸ¼: {cols_with_negative_values}\")\n",
    "\n",
    "    # 5. ë¡œê·¸ ë³€í™˜ (ìŒìˆ˜ ì»¬ëŸ¼ ì œì™¸)\n",
    "    for col in log_transform_cols:\n",
    "        if col not in cols_with_negative_values:\n",
    "            df_processed[col] = np.log1p(df_processed[col].clip(lower=0))  # ìŒìˆ˜ ë°©ì§€\n",
    "            print(f\"ğŸ“Š ë¡œê·¸ ë³€í™˜ ì ìš©: {col}\")\n",
    "\n",
    "    # 6. ìŠ¤ì¼€ì¼ë§ (StandardScaler)\n",
    "    scaler = StandardScaler()\n",
    "    if batch_size is None:\n",
    "        # ê¸°ë³¸ ë°©ì‹: ì „ì²´ ë°ì´í„° ìŠ¤ì¼€ì¼ë§\n",
    "        df_processed[numeric_cols] = scaler.fit_transform(df_processed[numeric_cols])\n",
    "        print(\"âœ… ì „ì²´ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ\")\n",
    "    else:\n",
    "        # ëŒ€ìš©ëŸ‰ ë°ì´í„°: ë°°ì¹˜ ì²˜ë¦¬\n",
    "        for start in range(0, len(df_processed), batch_size):\n",
    "            end = min(start + batch_size, len(df_processed))\n",
    "            df_processed.iloc[start:end, df_processed.columns.get_indexer(numeric_cols)] = \\\n",
    "                scaler.partial_fit(df_processed[numeric_cols].iloc[start:end]).transform(\n",
    "                    df_processed[numeric_cols].iloc[start:end]\n",
    "                )\n",
    "            print(f\"ğŸ“ˆ ë°°ì¹˜ ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: {start} ~ {end} í–‰\")\n",
    "\n",
    "    # 7. ì €ì¥ (ì˜µì…˜)\n",
    "    if save_path is not None:\n",
    "        df_processed.to_csv(save_path, index=False)\n",
    "        print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}\")\n",
    "\n",
    "    return df_processed, log_transform_cols, cols_with_negative_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd5447-91ef-4884-8edb-eab012719170",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-29T11:49:37.318Z",
     "iopub.execute_input": "2025-04-29T11:48:24.132923Z",
     "iopub.status.busy": "2025-04-29T11:48:24.132363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° í¬ê¸°: (2400000, 749)\n",
      "âš ï¸ Inf ê°’ì„ NaNìœ¼ë¡œ ëŒ€ì²´ í›„, NaN ë°œìƒ. í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´.\n"
     ]
    }
   ],
   "source": [
    "# í•¨ìˆ˜ í˜¸ì¶œ\n",
    "train_df = Scaler_data(train_df, save_path='train_cat_sacled')\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(f\"ë¡œê·¸ ë³€í™˜ëœ ì»¬ëŸ¼ ìˆ˜: {len(log_cols)}ê°œ\")\n",
    "print(f\"ìŒìˆ˜ê°’ ì¡´ì¬ ì»¬ëŸ¼ ìˆ˜: {len(negative_cols)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cae61-e5c5-48b9-b9de-7fa62d626396",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. ë¡œê·¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_ljh",
   "language": "python",
   "name": "py312_ljh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
